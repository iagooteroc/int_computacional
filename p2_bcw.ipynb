{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.discriminant_analysis import (LinearDiscriminantAnalysis,\n",
    "                                           QuadraticDiscriminantAnalysis)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import (pairwise_tukeyhsd,\n",
    "                                         MultiComparison)\n",
    "from statsmodels.sandbox.stats.multicomp import TukeyHSDResults\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos dataset Breast Cancer Wisconsin (Original)\n",
    "ds = pd.read_csv('./breast-cancer-wisconsin.data', usecols=[1,2,3,4,5,6,7,8,9,10], \n",
    "                 names=[0,1,2,3,4,5,6,7,8,9], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 9\n",
    "# Transformamos la columna de clases a 0-1 (actualmente son 2,4)\n",
    "ds[output] = np.uint8(ds[output]/2-1)\n",
    "y = ds[output].values\n",
    "X = ds.drop(output,axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprobamos que no haya \"missing values\"**  \n",
    "Según https://archive.ics.uci.edu/ml/datasets, los Missing Values están etiquetados como '?'.  \n",
    "Eliminamos las filas con dicho valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.argwhere(X == '?')[:,0]\n",
    "X = np.delete(X,rows,0)\n",
    "y = np.delete(y,rows)\n",
    "X = X.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr = []\n",
    "# Iteramos los atributos del dataset\n",
    "for i in ds.columns:\n",
    "    # Comprobamos los valores de cada atributo\n",
    "    attr.append(np.all(ds[i].notna()))\n",
    "# Ningún atributo tiene missing values:\n",
    "np.all(np.array(attr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprobamos que no haya variables con \"near-zero variance\"**  \n",
    "Vemos que no hay ninguna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns.drop(output)[ds.std() < 0.001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprobamos que no haya variables iguales**  \n",
    "Vemos que no hay ninguna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = np.zeros((len(ds.columns), len(ds.columns)))\n",
    "for i in range(len(ds.columns)):\n",
    "    for j in range(len(ds.columns)):\n",
    "        resultados[i, j] = np.mean(ds.iloc[:, i] == ds.iloc[:, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iguales = []\n",
    "for i, j in it.combinations(range(len(ds.columns)), 2):\n",
    "    if round(resultados[i, j], 4) == 1:\n",
    "        iguales.append(ds.columns[i])\n",
    "        print(ds.columns[i], ds.columns[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprobamos que las clases no estén desbalanceadas**  \n",
    "Están un poco desbalanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporción clase 0:  0.6500732064421669\n",
      "Proporción clase 1:  0.34992679355783307\n"
     ]
    }
   ],
   "source": [
    "print('Proporción clase 0: ',np.mean(y==0))\n",
    "print('Proporción clase 1: ',np.mean(y==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Desordenamos los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shuffle(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**kFold - Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "resultados_train = []\n",
    "resultados_valid = []\n",
    "model = []\n",
    "res_train = np.empty((30,0))\n",
    "res_valid = np.empty((30,0))\n",
    "test_indices = []\n",
    "etiquetas = ['DT Normal',\n",
    "             'DT Profundidad',\n",
    "             'DT Minimo de muestras por hoja',\n",
    "             'DT Minimo de muestras en subarbol',\n",
    "             'DT Minimo de impureza',\n",
    "             'LDA lsqr',\n",
    "             'LDA eigen',\n",
    "             'LDA svd',\n",
    "             'QDA']\n",
    "dicc = [{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_impurity_decrease': 0.0},\n",
    "        {'max_depth': 5,    'min_samples_leaf': 1, 'min_samples_split': 2, 'min_impurity_decrease': 0.0},\n",
    "        {'max_depth': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'min_impurity_decrease': 0.0},\n",
    "        {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_impurity_decrease': 0.0},\n",
    "        {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_impurity_decrease': 0.2}]\n",
    "\n",
    "for i in range(len(dicc)):\n",
    "    test_indices2 = []\n",
    "    for j in range(3):\n",
    "        for train_index, test_index in kf.split(X):\n",
    "    #         train_test_split del conjunto train y pillar 1/9 para validación\n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(X[train_index],y[train_index],test_size=1/9)\n",
    "            test_indices2.append(test_index)\n",
    "    #         print('X_train: {}\\n, X_valid: {}\\n, X_test: {}'.format(X_train, X_valid, X_test))\n",
    "            alg = DecisionTreeClassifier(**dicc[i])\n",
    "            alg.fit(X_train, y_train)\n",
    "            model.append(alg)\n",
    "            resultados_train.append(alg.score(X_train, y_train))\n",
    "            resultados_valid.append(alg.score(X_valid, y_valid))\n",
    "    res_train = np.hstack((res_train, np.array(resultados_train,ndmin=2).T))\n",
    "    res_valid = np.hstack((res_valid, np.array(resultados_valid,ndmin=2).T))\n",
    "    resultados_train = []\n",
    "    resultados_valid = []\n",
    "    test_indices.append(test_indices2)\n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**kFold - Linear Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tipo in ('lsqr', 'eigen', 'svd'):\n",
    "    test_indices2 = []\n",
    "    for _ in range(3):\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(X[train_index],y[train_index],test_size=1/9)\n",
    "            alg = LinearDiscriminantAnalysis(solver=tipo, shrinkage=None)\n",
    "            test_indices2.append(test_index)\n",
    "            alg.fit(X_train, y_train)\n",
    "            resultados_train.append(alg.score(X_train, y_train))\n",
    "            resultados_valid.append(alg.score(X_valid, y_valid))\n",
    "    res_train = np.hstack((res_train, np.array(resultados_train,ndmin=2).T))\n",
    "    res_valid = np.hstack((res_valid, np.array(resultados_valid,ndmin=2).T))\n",
    "    resultados_train = []\n",
    "    resultados_valid = []\n",
    "    test_indices.append(test_indices2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**kFold - Quadratic Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_indices2 = []\n",
    "for _ in range(3):\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X[train_index],y[train_index],test_size=1/9)\n",
    "        test_indices2.append(test_index)\n",
    "        alg = QuadraticDiscriminantAnalysis()\n",
    "        alg.fit(X_train, y_train)\n",
    "        resultados_train.append(alg.score(X_train, y_train))\n",
    "        resultados_valid.append(alg.score(X_valid, y_valid))\n",
    "res_train = np.hstack((res_train, np.array(resultados_train,ndmin=2).T))\n",
    "res_valid = np.hstack((res_valid, np.array(resultados_valid,ndmin=2).T))\n",
    "test_indices.append(test_indices2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test de normalidad**  \n",
    "Rechazamos normalidad, podriamos asumir normalidad con algún "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08643597, 0.00092715, 0.01363506, 0.12342015, 0.52661008,\n",
       "       0.00458925, 0.00469219, 0.06416523, 0.13037458])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.apply_along_axis(lambda x: stats.shapiro(x)[1], axis=0, arr=res_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test de Kruskal-Wallis**  \n",
    "Rechazamos que las precisiones sean similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KruskalResult(statistic=61.06698412440228, pvalue=2.8772245242723637e-10)\n"
     ]
    }
   ],
   "source": [
    "print(stats.kruskal(*zip(*list(res_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multiple Comparison of Means - Tukey HSD,FWER=0.05</caption>\n",
       "<tr>\n",
       "  <th>group1</th> <th>group2</th> <th>meandiff</th>  <th>lower</th>   <th>upper</th>  <th>reject</th>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0</td>      <td>1</td>    <td>0.0039</td>  <td>-0.018</td>  <td>0.0258</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0</td>      <td>2</td>    <td>-0.0198</td> <td>-0.0417</td> <td>0.0021</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0</td>      <td>3</td>     <td>-0.0</td>   <td>-0.0219</td> <td>0.0219</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0</td>      <td>4</td>    <td>-0.0425</td> <td>-0.0644</td> <td>-0.0206</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0</td>      <td>5</td>    <td>0.0058</td>  <td>-0.0161</td> <td>0.0277</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0</td>      <td>6</td>    <td>0.0077</td>  <td>-0.0142</td> <td>0.0296</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0</td>      <td>7</td>    <td>0.0077</td>  <td>-0.0142</td> <td>0.0296</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0</td>      <td>8</td>    <td>-0.0019</td> <td>-0.0238</td>  <td>0.02</td>    <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>1</td>      <td>2</td>    <td>-0.0237</td> <td>-0.0456</td> <td>-0.0018</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>1</td>      <td>3</td>    <td>-0.0039</td> <td>-0.0258</td>  <td>0.018</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>1</td>      <td>4</td>    <td>-0.0464</td> <td>-0.0683</td> <td>-0.0245</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>1</td>      <td>5</td>    <td>0.0019</td>   <td>-0.02</td>  <td>0.0238</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>1</td>      <td>6</td>    <td>0.0039</td>  <td>-0.018</td>  <td>0.0258</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>1</td>      <td>7</td>    <td>0.0039</td>  <td>-0.018</td>  <td>0.0258</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>1</td>      <td>8</td>    <td>-0.0058</td> <td>-0.0277</td> <td>0.0161</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>2</td>      <td>3</td>    <td>0.0198</td>  <td>-0.0021</td> <td>0.0417</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>2</td>      <td>4</td>    <td>-0.0227</td> <td>-0.0446</td> <td>-0.0008</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>2</td>      <td>5</td>    <td>0.0256</td>  <td>0.0037</td>  <td>0.0475</td>   <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>2</td>      <td>6</td>    <td>0.0275</td>  <td>0.0056</td>  <td>0.0494</td>   <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>2</td>      <td>7</td>    <td>0.0275</td>  <td>0.0056</td>  <td>0.0494</td>   <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>2</td>      <td>8</td>    <td>0.0179</td>  <td>-0.004</td>  <td>0.0398</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>3</td>      <td>4</td>    <td>-0.0425</td> <td>-0.0644</td> <td>-0.0206</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>3</td>      <td>5</td>    <td>0.0058</td>  <td>-0.0161</td> <td>0.0277</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>3</td>      <td>6</td>    <td>0.0077</td>  <td>-0.0142</td> <td>0.0296</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>3</td>      <td>7</td>    <td>0.0077</td>  <td>-0.0142</td> <td>0.0296</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>3</td>      <td>8</td>    <td>-0.0019</td> <td>-0.0238</td>  <td>0.02</td>    <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>4</td>      <td>5</td>    <td>0.0483</td>  <td>0.0264</td>  <td>0.0702</td>   <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>4</td>      <td>6</td>    <td>0.0502</td>  <td>0.0283</td>  <td>0.0721</td>   <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>4</td>      <td>7</td>    <td>0.0502</td>  <td>0.0283</td>  <td>0.0721</td>   <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>4</td>      <td>8</td>    <td>0.0406</td>  <td>0.0187</td>  <td>0.0625</td>   <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>5</td>      <td>6</td>    <td>0.0019</td>   <td>-0.02</td>  <td>0.0238</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>5</td>      <td>7</td>    <td>0.0019</td>   <td>-0.02</td>  <td>0.0238</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>5</td>      <td>8</td>    <td>-0.0077</td> <td>-0.0296</td> <td>0.0142</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>6</td>      <td>7</td>     <td>-0.0</td>   <td>-0.0219</td> <td>0.0219</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>6</td>      <td>8</td>    <td>-0.0097</td> <td>-0.0316</td> <td>0.0122</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>7</td>      <td>8</td>    <td>-0.0097</td> <td>-0.0316</td> <td>0.0122</td>   <td>False</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [str(i) for i in range(res_valid.shape[1]) for _ in range(res_valid.shape[0])]\n",
    "arr_valid = res_valid.flatten('F')\n",
    "resultados = pairwise_tukeyhsd(arr_valid,labels)\n",
    "resultados.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(720x432)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(resultados.plot_simultaneous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LDA eigen'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seleccionamos el que tiene mejor media y vemos en el anterior cuales son iguales\n",
    "best_group = np.argmax(np.mean(res_valid, axis = 0))\n",
    "etiquetas[best_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = resultados._results_table.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT Minimo de muestras en subarbol',\n",
       " 'DT Normal',\n",
       " 'DT Profundidad',\n",
       " 'LDA eigen',\n",
       " 'LDA lsqr',\n",
       " 'LDA svd',\n",
       " 'QDA']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1 = resultados[0].index('group1')\n",
    "group2 = resultados[0].index('group2')\n",
    "reject = resultados[0].index('reject')\n",
    "best_groups = []\n",
    "for row in resultados[1:]:\n",
    "    if (row[group1] == str(best_group) or row[group2] == str(best_group)) and not row[reject]:\n",
    "        best_groups.append(row[group1])\n",
    "        best_groups.append(row[group2])\n",
    "best_groups = set(best_groups)\n",
    "sorted([etiquetas[int(i)] for i in best_groups])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nos quedamos con el más sencillo**  \n",
    "El cual asumimos que es el Lineal Discriminant Analysis con lsqr (Minimos cuadrados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_indexes(CM, PositiveClass):\n",
    "    classNum = len(CM)\n",
    "    TP = CM[PositiveClass, PositiveClass]\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for real in range(classNum):\n",
    "        for predicted in range(classNum):\n",
    "            if (real != PositiveClass and predicted != PositiveClass):\n",
    "                TN += CM[real, predicted]\n",
    "            if (real != PositiveClass and predicted == PositiveClass):\n",
    "                FP += CM[real, predicted]\n",
    "            if (real == PositiveClass and predicted != PositiveClass):\n",
    "                FN += CM[real, predicted]\n",
    "    Sens = TP/(TP+FN)\n",
    "    Spec = TN/(TN+FP)\n",
    "    PPV = TP/(TP+FP)\n",
    "    NPV = TN/(TN+FN)\n",
    "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "    return Sens,Spec,PPV,NPV,ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sens: 0.92, Spec: 0.98, PPV: 0.97, NPV: 0.96, ACC: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Escogemos el modelo más simple de entre los mejores\n",
    "simple = etiquetas.index('LDA svd')\n",
    "tipo = 'svd'\n",
    "Sens_l = []\n",
    "Spec_l = []\n",
    "PPV_l = []\n",
    "NPV_l = []\n",
    "ACC_l = []\n",
    "for test_index in test_indices[simple]:\n",
    "    train_index = np.ones(y.shape, dtype=bool)\n",
    "    train_index[test_index] = False\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    alg = LinearDiscriminantAnalysis(solver=tipo, shrinkage=None)\n",
    "    alg.fit(X_train, y_train)\n",
    "    y_pred = alg.predict(X_test)\n",
    "    CM = confusion_matrix(y_test, y_pred)\n",
    "    Sens,Spec,PPV,NPV,ACC = performance_indexes(CM,1)\n",
    "    Sens_l.append(Sens)\n",
    "    Spec_l.append(Spec)\n",
    "    PPV_l.append(PPV)\n",
    "    NPV_l.append(NPV)\n",
    "    ACC_l.append(ACC)\n",
    "print(('Sens: {:.2f}, Spec: {:.2f}, ' +\n",
    "       'PPV: {:.2f}, NPV: {:.2f}, ACC: {:.2f}').format(np.mean(Sens_l),\n",
    "                                                       np.mean(Spec_l),\n",
    "                                                       np.mean(PPV_l),\n",
    "                                                       np.mean(NPV_l),\n",
    "                                                       np.mean(ACC_l)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**----------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('RForest_Zika_oversampled.bin','wb') as file:\n",
    "#     pickle.dump(alg_o, file)\n",
    "# with open('RForest_Zika_undersampled.bin','wb') as file:\n",
    "#     pickle.dump(alg_u, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
